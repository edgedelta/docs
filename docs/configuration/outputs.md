---
description: >-
  This document outlines the various Output types (Streaming, Triggers and
  Archives) supported by the Edge Delta agent, and how the outputs are
  configured.
---

# Outputs

## Overview

You can use this document to learn about the configuration parameters available in a configuration file, specifically for **Outputs**.

An output tells the Edge Delta agent where to send collected and generated data, such as as metrics, patterns, alerts, etc.

> **Note**
> 
> The terms **output**, **integration**, and **destination** may be used interchangeably. 

At a high level, there are 3 types of outputs:

| Output Type | Description | Supported Platforms and Systems |
| :--- | :--- | :--- | 
| Streaming destinations | This output type focuses on centralized monitoring platforms. | Sumo Logic, AWS CloudWatch, Datadog, New Relic, InfluxDB, Wavefront, Scalyr, Elastic Search, Azure AppInsight, Kafka, SignalFx, Humio, Loggly, Logz.io, Loki | 
| Trigger destinations | This output type focuses on alerting and automation systems. Specifically, this output type allows Edge Delta to send alerts and notifications when an anomaly is detected or when various conditions are met.  | Slack, Microsoft Teams, Pagerduty, Jira, Service Now, Webhook, AWS Lambda, Azure Functions |
| Archive destinations | This output type focuses on storage solutions where Edge Delta can periodically send compressed raw data logs.  | AWS S3, Azure Blob Storage, Google Cloud Storage, DigitalOcean Spaces, IBM Object Storage, Minio, Zenko CloudServer, Moogsoft, Remedy, Azure Event Hub Trigger |

***

## Step 1: Access Outputs

At a high level, there are 2 ways to manage **Outputs**:

  * If you need to create a new configuration, then you can use the visual editor to populate a YAML file, as well as make changes directly in the YAML file.
  * If you already have an existing configuration, then you can update the configuration in the YAML file. 

***

### Option 1: Access the visual editor for a new configuration

1. In the Edge Delta Admin portal, on the left-side navigation, click **Agent Settings**.
2. Click **Create Configuration**.
3. Click **Visual**.
4. On the right-side, select **Streams**, **Triggers**, or **Archives**. 
5. Select the desired destination, and then complete the missing fields. 

  * To learn more about each destination, see Step 2: 

6. To make additional configurations to the configuration file, click the back button, and then select a new configuration parameter to manage. 
7. To save the configuraiton and exit the visual editor, click **Save**. 
8. Refresh the screen to view the newly created configuration in the table. 

***

### Option 2: Access the YAML file for an existing configuration

1. In the Edge Delta Admin portal, on the left-side navigation, click **Agent Settings**.
2. Locate the desired configuration, and then under **Actions**, click the corresponding edit icon.
3. Review the YAML file, make your changes, and then click **Save**. 

***




***

## Review Collected Data Types

When you create an output, you have the option to configure which data types the Edge Delta agent should collect / generate and send to a streaming destination. 

| Feature Type | Description | 
| :--- | :--- | 
| metric | This feaure type sends metrics that are generated by processors in the workflow. By default, this feature type is enabled. | 
| edac | This feature type sends contextual logs that happened around an anomaly. edac represents Edge Delta Anomaly Context. By default, this feature type is enabled.  | 
| cluster | This feature type sends cluster patterns and samples. Patterns are sent in the following format: "{cluster-pattern}, {count}" By default, this feature type is enabled.  | 
| logs | This feaure type forwards raw logs to a stream destination. | 
| topk | This feaure type send top-k records that are generated by the top-k processor. | 
| all | This feaure type enables the **metric**, **edac**, and **cluster** features for streaming destinations. | 

***

## Review Streaming Destinations

Edge Delta supports the following streaming destinations: 

### Splunk

The Splunk output will stream analytics and insights to a Splunk HEC endpoint. 

In the Edge Delta Admin portal, in the visual editor, when you select **Splunk** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Required |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **splunk**. | Required |
| endpoint | Enter the full Splunk HEC URI for this integration. | Required |
| token | Enter the Splunk HEC token for this integration. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **metric,edac,cluster** will be set. | Optional |


The following example displays an output without the name of the organization-level integration:

```yaml
      - name: splunk-integration
        type: splunk
        endpoint: "<protocol>://<host>:<port>/<endpoint>"
        token: "32-character GUID token"
        index: "main"
```

The following example displays if enter the name of the organization-level integration:

```yaml
      - integration_name: my-org-splunk
```

The following example displays if there are multiple instances of the same desitnation that need to route different data types to different Splunk indexes: 

```yaml
- name: edac-splunk-dest
  integration_name: orgs-splunk
  features: edac
  index: edac-index
- integration_name: orgs-splunk
  name: metric-splunk-dest
  features: metric
  index: metric-index
```

#### Setting up the Splunk Integration

The process is different between Splunk Cloud and Splunk Enterprise, so it is essential to follow the appropriate instructions for your environment

There are 3 important elements to your configuration:

* Configure an HEC Token in Splunk
* Determine the Correct HEC Endpoint in Splunk
* Import the Edge Delta dashboard into Splunk

#### Configuring an HEC Token in Splunk

##### Splunk Cloud
* Create a Splunk HTTP Event Collector (HEC) and Token
* In the Splunk Web UI, navigate to Settings -> Add Data
* Click “Monitor” -> “HTTP Event Listener”
* Provide a name for the HEC in the name field -> Click “Next”
* Confirm Index information or use default index -> “Click Review”
* Click “Submit”
* Copy the Token Value displayed in the Splunk Web into the “Token” field of the Edge Delta - Splunk Streaming Destination Configuration

##### Splunk Enterprise

* Ensure HTTP Event Collector (HEC) is enabled
* In the Splunk Enterprise Web UI, navigate to Settings -> Data Inputs
* Click “HTTP Event Collector”
* Click “Global Settings”
* In the “All Tokens” toggle button, select “Enabled”
* Create a Splunk HTTP Event Collector (HEC) and Token
* In the Splunk Web UI, navigate to Settings -> Add Data
* Click “Monitor” -> “HTTP Event Collector”
* Provide a name for the HEC in the name field -> Click “Next”
* Confirm Index information or use default index -> “Click Review”
* Click “Submit”
* Copy the Token Value displayed in the Splunk Web into the “Token” field of the Edge Delta - Splunk Streaming Destination Configuration


#### Determining your HEC Endpoint

Before continuing, please ensure you have gathered the following information:

* Splunk deployment type (Enterprise, Cloud, Free Trial, etc)
* Splunk hostname (from Splunk Browser URI) 
* Input  Protocol (HTTPS is default)

##### Splunk Cloud (Cloud, Free Trial, Cloud on GCP) Format

Replace <splunk_hostname> with your organization’s hostname

* Splunk Cloud
  * URI Format: https://http-inputs-<splunk_hostname>:443/services/collector/event
* Splunk Free Trial 
  * URI Format: https://inputs.<splunk_hostname>:8088/services/collector/event
* Splunk Cloud on GCP
  * URI Format: https://http-inputs.<splunk_hostname>:443/services/collector/event

##### Splunk Enterprise

* URI Format: https://<splunk_hostname>:8088/services/collector/event


#### How to import the Edge Delta Dashboard

Import this dashboard into your Splunk environment for a real-time overview of your data from Edge Delta.

* Navigate to Search UI
* Click “Dashboards”
* Click “Create New Dashboard”
* Input Dashboard Name/Description/Permissions
* Click “Classic Dashboards” -> “Create”
* In the Edit Dashboard Screen, switch from UI to Source
* Replace existing XML with copied XML from clipboard
* Switch back to UI (instead of source)
* Click “Save”


### Sumo Logic

The Sumo Logic output will stream analytics and insights to a Sumo Logic HTTPs Endpoint.

> **Before you begin**
> 
> Before you can create an output, you must have available the Sumo Logic HTTPs Endpoint.
> To learn how to create new Sumo Logic HTTPs endpoint, review this [document from Sumo Logic](https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/HTTP-Source#access-a-sources-url). 
> To learn how to locate an existing Sumo Logic HTTPs endpoint, review this [document from Sumo Logic](https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/HTTP-Source#access-a-sources-url).

In the Edge Delta Admin portal, in the visual editor, when you select **Sumo Logic** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional|
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **sumologic**. | Required |
| endpoint | Enter the full HTTPs URL for this endpoint. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:
 

```yaml
      - name: sumo-logic-integration
        type: sumologic
        endpoint: "https://[SumoEndpoint]/receiver/v1/http/[UniqueHTTPCollectorCode]"
```

***

### AWS CloudWatch

The AWS CloudWatch output will stream logs to a specified AWS region.  

> **Before you begin**
> 
> Before you can create an output, you must have available the CloudWatch log group name and log stream name.
> To learn how to create a log group, review this [document from Amazon](https://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_CreateLogGroup.html).
> To learn how to create a log stream, review this [document from Amazon](https://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_CreateLogStream.html).

In the Edge Delta Admin portal, in the visual editor, when you select **AWS CloudWatch** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional|
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **cloudwatch**. | Required |
| region | Enter the AWS region destination to send logs. | Required |
| log\_group\_name | Enter the CloudWatch log group name. | Required |
| log\_stream\_name | Enter the CloudWatch log stream name. You can enter a name or prefix, but not both. | Required |
| log\_stream\_prefix | Enter the CloudWatch log stream prefix. You can enter a name or prefix, but not both.  | Required |
| auto\_create | When necessary iam policies provided if auto\_create is set, log group and log stream will be created if not exists | Optional |
| allow\_label\_override | monitored container can override the default values of log group name, logs stream name and log stream prefix, by setting ed\_log\_group\_name, ed\_log\_stream\_name, ed\_log\_stream\_prefix labels | Optional |
| auto\_configure | only supported for ECS environments, and when provided only region configuration can be provided. Automatically create LogGroupName in the format of /ecs/task\_definition\_family and LogsStreamPrefix in the format of ecs/container\_name/task\_id | Optional |
| type | Streaming destination type \(i.e. sumologic, datadog, splunk, etc.\) | Required |
| features | This parameter defines which data types to stream to the backend. For Amazon CloudWatch, you can only select **log**. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: cloudwatch
        type: cloudwatch
        region: us-west-2
        log_group_name: /ecs/microservice
        log_stream_prefix: ecs
        auto_create: true
        features: log
```

* Assign below permission to taskExecutionRoleArn for putting log events into CloudWatch when auto\_create is not set

  ```yaml
      {
        "Version": "2012-10-17",
        "Statement": [{
          "Effect": "Allow",
          "Action": [
            "logs:PutLogEvents"
          ],
          "Resource": "*"
        }]
      }
  ```

* Assign below permission to taskExecutionRoleArn if auto\_create is set

  ```yaml
      {
        "Version": "2012-10-17",
        "Statement": [{
          "Effect": "Allow",
          "Action": [
            "logs:CreateLogStream",
            "logs:CreateLogGroup",
            "logs:DescribeLogStreams",
            "logs:PutLogEvents"
          ],
          "Resource": "*"
        }]
      }
  ```





***


### Datadog

The Datadog output will stream analytics and insights to a Datadog environment. 

> **Before you begin**
> 
> Before you can create an output, you must have available a Datadog API Key.
> To learn how to create a new Datadog API key, review this [document from Datadog](https://docs.datadoghq.com/account_management/api-app-keys/#add-a-key).

In the Edge Delta Admin portal, in the visual editor, when you select **Datadog** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **datadog**. | Required |
| log_host | If provided, custom installation of Datadog log host to send log data. | Optional |
| metric_host | If provided, custom installation of Datadog metric host to send metric data. | Optional |
| api\_key | Enter a Datadog API key. | Yes |
| custom\_tags | Key-values defined in custom tags by the user are streamed to datadog for every request. | Optional |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |


The following example displays an output without the name of the organization-level integration:

```yaml
      - name: datadog-integration-default
        type: datadog
        api_key: "<add datadog api key>"
        custom_tags:
          "app": "transaction_manager"
          "env": "pre_prod"
          "region": "us-west-2"

      - name: datadog-integration-custom
        type: datadog
        # If provided, custom installation of datadog log host can be reached.
        log_host: "<ADD DATADOG LOG_HOST>"
        # If provided, custom installation of datadog metric host can be reached.
        metric_host: "<ADD DATADOG METRIC_HOST>"
        api_key: "<add datadog api key>"
        features: metric
        custom_tags:
          "app": "transaction_manager"
          "region": "us-west-2"
```

***

### New Relic

The New Relic output will stream analytics and insights to a New Relic environment.

> **Before you begin**
> 
> Before you can create an output, you must have available the New Relic Insert API key. 
> To learn how to create new New Relic Insert API key, review this [document from New Relic](https://docs.newrelic.com/docs/apis/get-started/intro-apis/types-new-relic-api-keys#event-insert-key).

In the Edge Delta Admin portal, in the visual editor, when you select **New Relic** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **newrelic**. | Required |
| api\_key | Enter a New Relic Insert API key. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set.  | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: new-relic-integration
        type: newrelic
        api_key: "<add new relic insert api key>"
```

***

### InfluxDB

The InfluxDB output will stream analytics and insights to your InfluxDB deployment.

In the Edge Delta Admin portal, in the visual editor, when you select **InfluxDB** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **influxdb**. | Required |
| version | Enter the version number of the InfluxDB deployment. This parameter supports versions 1.x and 2.x. An empty version will default to version 2.x | Optional |
| bucket | Enter the InfluxDB bucket to send archived logs to. This parameter is only required for version 2.x. | Required |
| organization | Enter the InfluxDB buckets for customer organization. This parameter is only required for version 2.x. | Required |
| endpoint | Enter the InfluxDB endpoint. | Required |
| http\_user | Enter the InfluxDB user credentials. This parameter is only required for version 1.x. | Required |
| http\_password | Enter the InfluxDB password for connecting user. This parameter is only required for version 1.x. | Required |
| db | Enter the InfluxDB database to stream data to. This parameter is only required for version 1.x. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: influxdb-integration
        type: influxdb
        endpoint: "https://influxdb.<your-domain>.com/"
        port: 443
        http_user: admin
        http_password: your_http_password
        db: "specific_influxdb_database"
      
      - name: influxdb-integration-2.x
        type: influxdb
        endpoint: "https://influxdb.<your-domain>.com/"
        token: YOUR_API_TOKEN
        # empty version or version 2.x requires bucket and organization info
        bucket: testbucket
        organization: yourorganization
        port: 443
```

***

### Wavefront

The Wavefront output will stream analytics and insights to your Wavefront environment.

In the Edge Delta Admin portal, in the visual editor, when you select **Wavefront** as the output type, the following fields will appear:


| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow.  | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | Optional |
| type | Select **wavefront**. | Required |
| endpoint | Enter the Wavefront endpoint. | Required |
| token | Enter the Wavefront API token. | Required |
| features | This parameter defines which data types to stream to the backend. For Wavefront, you can only select **metric**. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: wavefront-integration
        type: wavefront
        endpoint: "https://{your wavefront domain}.wavefront.com/report"
        token: "<add wavefront api token>"
```

***

### Scalyr

The Scalyr output will stream analytics and insights to your Scalyr environment.

In the Edge Delta Admin portal, in the visual editor, when you select **Scalyr** as the output type, the following fields will appear:


| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | Optional |
| type | Select **scalyr**.| Required |
| endpoint | Enter the Scalyr endpoint. | Required |
| features | This parameter defines which data types to stream to the backend. For Scalyr, you can only select **log**. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: scalyr-integration
        type: scalyr
        endpoint: "https://app.scalyr.com/api/uploadLogs?token={scalyr log access write key}"
```

***

### Elastic Search

The **Elastic Search** output will stream analytics and insights to your Elastic Search environment. 

> **Note**
> 
> Edge Delta recommends that you review and complete the steps listed in the [elastic index template and lifecycle creation guide](../appendices/elastic-index.md). This process will help you prepare your Elastic Search environment to become an Edge Detla streaming target.

> Note
> 
> For **connection url**, you must provide either the **cloud\_id** or **address**. You cannot enter both parameters. 
> For the **authentication**, you must provide either the **token** or the **user/password**. You cannot enter both parameters. 

In the Edge Delta Admin portal, in the visual editor, when you select **Elastic Search** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **elastic**. | Required |
| index | Enter the name of the Elastic index \(or index template\) where Edge Delta should stream the data. If you followed the guide mentioned above, then set this parameter to **ed-agent-log**. | Required |
| cloud\_id | Enter the cloud ID of the Eastic Search backend. | Optional |
| address | Enter the address list of the Eastic Search backend. | Optional |
| token | Enter the Eastic Search API key. | Optional |
| user | Enter the username of the Elastic Search credentials. | Optional |
| password | Enter the password for the connecting user. | Optional |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: elastic-integration
        type: elastic
        index: "index name"
        # you can provide cloud or adress list but not both at the same time
        cloud_id: "<add elasticsearch cloud_id>"
        #address:
         #- <elastic search endpoint address_1>
         #- <elastic search endpoint address_2>
        # you can provide token or user/pass for auth but not both at the same time
        token: "elastic search api key"
        #user: "elastic search username"
        #password: "elastic search password"
```

***

### Azure AppInsight

The **Azure AppInsight** output will stream analytics and insights to your Azure endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Azure AppInsight** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **azure**. | Required |
| endpoint | Enter the Azure AppInsight endpoint. | Required |
| api\_key | Enter the Azure AppInsight API key. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: azure-integration
        type: azure
        endpoint: https://dc.services.visualstudio.com/v2/track
        api_key: "Azure AppInsight api key" 
        features: "metric"
```

***

### Kafka

The **Kafka** output will stream analytics and insights to your Kafka endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Kafka** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **kafka**. | Required |
| endpoint | Enter your Kafka broker addresses. | Required |
| topic | Enter your Kafka topic name. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: kafka-integration
        type: kafka
        endpoint: https://dc.services.visualstudio.com/v2/track
        endpoint: <kafka broker address-1>,<kafka broker address-2>
        topic: topic
```

***

### SignalFx

The **SignalFx** output will stream analytics and insights to your SignalFx endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **SignalFx** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow.  | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows.  | Optional |
| type | Select **signalfx**. | Required |
| endpoint | Enter your SignalFx endpoint. | Required |
| token | Enter your SignalFx API token. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: signalfx-integration
        type: signalfx
        endpoint: https://ingest.us1.signalfx.com/v2
        token: "<add signalfx api token>"
        features: "metric,log"
```

***

### Humio

The **Humio** output will stream analytics and insights to your Humio endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Humio** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | Optional |
| type | Select **humio**. | Required |
| endpoint | Enter the Humio endpoint. You can use a cloud endpoint or a self-hosted endpoint. | Required |
| token | Enter the Humio API token. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: humio-integration
        type: humio
        endpoint: http://localhost:8080
        token: "<add humio api token here>"
        features: "metric,log"
```

***

### Loggly

The **Loggly** output will stream analytics and insights to your Loggly endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Loggly** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional|
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | Optional |
| type | Select **loggly**. | Required |
| endpoint | Enter a Loggly endpoint. You can use a cloud endpoint or a self-hosted endpoint. The default endpoint is https://logs-01.loggly.com. | Required |
| token | Enter a Loggly API token. | Required |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: loggly-integration
        type: loggly
        endpoint: https://logs-01.loggly.com
        token: "<add loggly api token here>"
        features: "metric,log"
```

***

### Logz.io

The **Logz.io** output will stream analytics and insights to your Logz.io endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Logz.io** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | Optional |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | Optional |
| type | Select **logzio**. | Required |
| endpoint | Enter the Logz.io endpoint. You can use a cloud endpoint or a self-hosted endpoint. | Required |
| token | Enter the Logz.io log token. This parameter is required if you want to support log stream. | Optional |
| metric_token | Enter the Logz.io metric token. This parameter is required if you want to support metric stream. | Optional |
| custom\_tags | With this parameter, you can create key-values to stream to Logz.io with every request. | Optional |
| features | This parameter defines which data types to stream to the backend. If you do not provide a value, then **all** will be set. | Optional |

The following example displays an output without the name of the organization-level integration:

```yaml
      - name: logzio
        type: logzio
        endpoint: "https://app-eu.logz.io:8071"
        token: "<add logz.io log shipping token>"
        metric_token: "<add logz.io metric shipping token>"
        custom_tags:
          "app": "starbucks_pos_transaction_manager"
          "region": "us-west-2"
```

***

### Loki

The **Loki** output will stream analytics and insights to your Loki endpoint.

In the Edge Delta Admin portal, in the visual editor, when you select **Loki** as the output type, the following fields will appear:

| Parameter | Description | Required or Optional |
| :--- | :--- | :--- |
| name | Enter a descriptive name for the output, which will be used to map this destination to a workflow. | No |
| integration\_name | This parameter refers to the organization-level integration created in the **Integrations** page. If you enter this name, then the rest of the fields will be automatically populated. If you need to add multiple instances of the same integration into the config, then you can add a custom name to each instance via the **name** field. In this situation, the name should be used to refer to the specific instance of the destination in the workflows. | No |
| type | Select loki. | Yes |
| endpoint | Enter the Loki endpoint. | Yes |
| api\_key | Enter the Loki API key.  | Yes |
| user | Enter the username for Loki. | Yes |
| custom\_tags | With this parameter, you can create key-values to stream to Loki with every request. This parameter supports templating. | No |
| message\_template | This parameters customizes the message content. This parameter supports templating. | No |
| features | This parameter defines which data types to stream to the backend. You can select **log**, **edac**, and / or **cluster**. | No |

#### **Message Template**

As an optional step, you can customize the message payload and custom tags that are sent to Loki destinations. 
  * Loki does not support the "-" character as a key value.

Review the following avaialble template fields: 

| Field | Description |
| :--- | :--- | 
| Tag | This field is the user-defined tag that describes the environment, such as . prod\_us\_west\_2\_cluster. | 
| Host | This field is the hostname of the environment where the agent is running on. | 
| ConfigID | This field is the configuration ID of the corresponding agent. | 
| Source | This field is the source name, specifically the identifier of the source, such as docker container id or file name. | 
| SourceType | This field is the source type, such as "Docker" or "system." | 
| FileGlobPath | This field is the file global path. | 
| K8sPodName | This field is the Kubernetes pod name. | 
| K8sNamespace | This field is the Kubernetes namespace. | 
| K8sControllerKind | This field is the Kubernetes controller kind. | 
| K8sContainerName | This field is the Kubernetes container name. | 
| K8sContainerImage | This field is the Kubernetes container image. | 
| K8sControllerLogicalName | This field is the Kubernetes controller logical name. | 
| ECSCluster | This field is the ECS cluster name. | 
| ECSContainerName | This field is the ECS container name. | 
| ECSTaskVersion | This field is the ECS task version. | 
| ECSTaskFamily | This field is the ECS task family. | 
| DockerContainerName | This field is the Docker container name. | 

Review the following example: 

```yaml
      - name: loki-integration
        type: loki
        endpoint: "https://localhost:3000/loki/api/v1/push"
        api_key: "api_key"
        user: "user"
        custom_tags:
          "app": "test"
          "region": "us-west-2"
        message_template:
          "File Path": "{{.FileGlobPath}}"
          "K8s PodName": "{{.K8sPodName}}"
          "K8s Namespace": "{{.K8sNamespace}}"
          "K8s ControllerKind": "{{.K8sControllerKind}}"
          "K8s ContainerName": "{{.K8sContainerName}}"
          "K8s ContainerImage": "{{.K8sContainerImage}}"
          "K8s ControllerLogicalName": "{{.K8sControllerLogicalName}}"
          "ECSCluster": "{{.ECSCluster}}"
          "ECSContainerName": "{{.ECSContainerName}}"
          "ECSTaskVersion": "{{.ECSTaskVersion}}"
          "ECSTaskFamily": "{{.ECSTaskFamily}}"
          "DockerContainerName": "{{.DockerContainerName}}"
          "ConfigID": "{{.ConfigID}}"
          "Host": "{{.Host}}"
          "Source": "{{.Source}}"
          "SourceType": "{{.SourceType}}"
          "Tag": "{{.Tag}}"
```

***

### FluentD

You can enable this integration to stream analytics and insights to a FluentD endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | This key is the user-defined name of the specific destination. This key is used for mapping this destination to a workflow. | No |
| integration\_name | This key refers to the organization-level integration created on the [Integrations page](https://admin.edgedelta.com/integrations). This key can be referred in the rest of the config via _integration\_name_ . In this case, the rest of the fields are not required to be set because the additional fields are auto-populated from the organization-level integration spec. If there are multiple instances in the same integration that need to be added to a config, then you can create a custom name for each instance via the via _name_ field. In this case, each name should be used to refer to a destination's specific instance in the workflow. | No |
| type | This key must be set to "fluentd" to stream data to FluentD. | Yes |
| host | This key is the FluentD host. This key is required if you want to support tcp stream. | Yes |
| port | This key is the FluentD port. This key is required if want to support tcp stream. | Yes |
| encoder | This key is the encoder type to use while streaming data to FluentD. Raw and 'msgpack' are supported. | No |
| features | This key defines which data types to stream to the backend. You can set this key to "log", "metric," "edac," "cluster," "topk," and / or "all". If you do not provide a value, then "all" is used. | No |

```yaml
      - name: fluentd-log-fwd
        type: fluentd
        host: log-repo-host
        port: 23131
        encoder: msgpack
        pool_size: 10
        features: log
```

### Azure Event Hub Stream

You can enable this integration to stream analytics and insights to an Azure Event Hub endpoint.

> **Note**
> 
> To enable this integration, you must have an Azure AD token. To learn how to create an Azure AD token, review this [document from Microsoft](https://docs.microsoft.com/en-us/rest/api/eventhub/get-azure-active-directory-token).

| Key | Description | Required |
| :--- | :--- | :--- |
| name | This key is the user-defined name of the specific destination. This key is used for mapping this destination to a workflow. | No |
| integration\_name | This key refers to the organization-level integration created on the [Integrations page](https://admin.edgedelta.com/integrations). This key can be referred in the rest of the config via _integration\_name_ . In this case, the rest of the fields are not required to be set because the additional fields are auto-populated from the organization-level integration spec. If there are multiple instances in the same integration that need to be added to a config, then you can create a custom name for each instance via the via _name_ field. In this case, each name should be used to refer to a destination's specific instance in the workflow. | No |
| type | This key must be set to "eventhubstream" to stream data to Azure Event Hub. | Yes |
| endpoint | This key is the Event Hub endpoint. | Yes |
| token | This key is the Azure AD token. | Yes |
| features | This key defines which data types to stream to the  backend, You can set this key to "log," "metric," "edac," "cluster," "topk," "alert," and / or "all". If you do not provide a value, then "all" is used. | No |

```yaml
      - name: eventhub-stream
        type: eventhubstream
        endpoint: "https://namespace.servicebus.windows.net/hub/messages"
        token: "azure-ad-token"
        features: log,metric
```

## Review Trigger Destinations 

### **Slack**

If enabled, the Slack integration will stream notifications and alerts to the specified Slack channel

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "slack" to send alerts to Slack | Yes |
| endpoint | Slack Webhook or APP endpoint URL | Yes |
| suppression\_window | A [golang duration](https://golang.org/pkg/time/#ParseDuration) string that represents the suppression window. Once agent detects an issue and notifies this slack endpoint it will suppress any new issues for this duration. Default is "20m". | No |
| suppression\_mode | Suppression mode can be "local" or "global". Default is "local" which means an individual agent suppresses an issue only if it has locally notified a similar issue in last suppresson window. When "global" mode is selected an individual agent checks with Edge Delta backend to see whether there were similar alerts from other sibling agents \(the ones sharing same tag in config\). | No |
| notify\_content | Used to customize the notification content. It supports templating. | No |

```yaml
      - name: slack-integration
        type: slack
        endpoint: "https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX"
        notify_content:
          title: "Anomaly Detected: {{.ProcessorDescription}}"
          disable_default_fields: false
          custom_fields:
            "Dashboard": "https://admin.edgedelta.com/investigation?edac={{.EDAC}}&timestamp={{.Timestamp}}"
            "Current Value": "{{.CurrentValue}}"
            "Threshold Value": "{{.ThresholdValue}}"
            "Custom Message": "{{.CurrentValue}} exceeds {{.ThresholdValue}}"
            "Matched Term": "{{.MatchedTerm}}"
```

**Getting started with Slack Incoming Webhooks:** [https://api.slack.com/messaging/webhooks](https://api.slack.com/messaging/webhooks)

### **Microsoft Teams**

If enabled, the Microsoft Teams integration will stream notifications and alerts to the specified Teams channel using hook URL

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "teams" to send alerts to Microsoft Teams | Yes |
| endpoint | Microsoft Teams Webhook URL | Yes |
| suppression\_window | A [golang duration](https://golang.org/pkg/time/#ParseDuration) string that represents the suppression window. Once agent detects an issue and notifies this Microsoft Teams endpoint it will suppress any new issues for this duration. Default is "20m". | No |
| suppression\_mode | Suppression mode can be "local" or "global". Default is "local" which means an individual agent suppresses an issue only if it has locally notified a similar issue in last suppresson window. When "global" mode is selected an individual agent checks with Edge Delta backend to see whether there were similar alerts from other sibling agents \(the ones sharing same tag in config\). | No |
| notify\_content | Used to customize the notification content. It supports templating. | No |

```yaml
      - name: microsoft-teams-integration
        type: teams
        endpoint: "https://outlook.office.com/webhookb2/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX@XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/IncomingWebhook/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
        notify_content:
          title: "Anomaly Detected: {{.ProcessorDescription}}"
          disable_default_fields: false
          custom_fields:
            "Dashboard": "https://admin.edgedelta.com/investigation?edac={{.EDAC}}&timestamp={{.Timestamp}}"
            "Current Value": "{{.CurrentValue}}"
            "Threshold Value": "{{.ThresholdValue}}"
            "Custom Message": "{{.CurrentValue}} exceeds {{.ThresholdValue}}"
            "Matched Term": "{{.MatchedTerm}}"
```

#### **Notify Content**

Notify Content is optional way to customize the notification content for some (such as Slack, Microsoft Teams, Webhook etc.) triggers. It supports templating.
 **Available template fields**:

* **Tag**: User defined tag to describe the environment. e.g. prod\_us\_west\_2\_cluster.
* **EDAC**: Edge Delta Anomaly Context ID.
* **Host**: Hostname of the environment where agent running on.
* **ConfigID**: Configuration ID which agent is using.
* **MetricName**: Metric name causing the anomaly.
* **Source**: Source name is the identifier of the source such as docker container id or file name.
* **SourceType**: Source type. e.g. "Docker", "system"
* **SourceAttributes**: List of source attributes.
* **Timestamp**: Timestamp when event triggered.
* **Epoch**: Timestamp in epoch format when event triggered. [epoch](https://en.wikipedia.org/wiki/Epoch)
* **CurrentValue**: Metric current value.
* **ThresholdValue**: Threshold value.
* **ThresholdDescription**: Detailed threshold description including threshold type, value, etc.
* **MatchedTerm**: A sample log message causing the anomaly event.
* **ThresholdType**: Threshold type.
* **FileGlobPath**: File global path.
* **K8sPodName**: Kubernetes pod name.
* **K8sNamespace**: Kubernetes namespace.
* **K8sControllerKind**: Kubernetes controller kind.
* **K8sContainerName**: Kubernetes container name.
* **K8sContainerImage** Kubernetes container image.
* **K8sControllerLogicalName**: Kubernetes controller logical name.
* **ECSCluster**: ECS cluster name.
* **ECSContainerName**: ECS container name.
* **ECSTaskVersion**: ECS task version/
* **ECSTaskFamily**: ECS task family.
* **DockerContainerName**: Docker container name.

  _Note:_ About templates you should read before use:

* if the value is empty the item will not be sent to slack
* the keys are sorted alphabetically before sending to slack so they will not appear in the order specified in the config

**Title**: Title text for webhook message. It can be customized with custom template fields.
 **Disable default fields**: It is used for disabling default fields in notify message. Its value is false by default.
 **Custom Fields**: You can extend the notification content by adding name-value pairs. You can build by using template fields given above.
 **Advanced Content**: It provides full flexibility to define the payload in slack notification post requests.

* Advanced content overrides the other settings\(title, custom fields...\)
* Custom templates are also supported in advanced content.
* You can use block kit builder tool provided by Slack [https://app.slack.com/block-kit-builder](https://app.slack.com/block-kit-builder) prior to test.

```yaml
       notify_content:
         title: "Anomaly Detected: {{.ProcessorDescription}}"
         disable_default_fields: false
         custom_fields:
           "Dashboard": "https://admin.edgedelta.com/investigation?edac={{.EDAC}}&timestamp={{.Timestamp}}"
           "Current Value": "{{.CurrentValue}}"
           "Threshold Value": "{{.ThresholdValue}}"
           "Custom Message": "{{.CurrentValue}} exceeds {{.ThresholdValue}}"
           "Built-in Threshold Description": "{{.ThresholdDescription}}"
           "Matched Term": "{{.MatchedTerm}}"
           "Threshold Type": "{{.ThresholdType}}"
           "File Path": "{{.FileGlobPath}}"
           "K8s PodName": "{{.K8sPodName}}"
           "K8s Namespace": "{{.K8sNamespace}}"
           "K8s ControllerKind": "{{.K8sControllerKind}}"
           "K8s ContainerName": "{{.K8sContainerName}}"
           "K8s ContainerImage": "{{.K8sContainerImage}}"
           "K8s ControllerLogicalName": "{{.K8sControllerLogicalName}}"
           "ECSCluster": "{{.ECSCluster}}"
           "ECSContainerName": "{{.ECSContainerName}}"
           "ECSTaskVersion": "{{.ECSTaskVersion}}"
           "ECSTaskFamily": "{{.ECSTaskFamily}}"
           "DockerContainerName": "{{.DockerContainerName}}"
           "SourceAttributes": "{{.SourceAttributes}}"
           "ConfigID": "{{.ConfigID}}"
           "EDAC": "{{.EDAC}}"
           "Epoch": "{{.Epoch}}"
           "Host": "{{.Host}}"
           "MetricName": "{{.MetricName}}"
           "Source": "{{.Source}}"
           "SourceType": "{{.SourceType}}"
           "Tag": "{{.Tag}}"
```

```yaml
       notify_content:
         title: "Anomaly Detected: {{.ProcessorDescription}}"
         advanced_content: |
           {
             "blocks": [
               {
                 "type": "section",
                 "text": {
                   "type": "mrkdwn",
                   "text": "*Raw POST Anomaly Detected: {{.ProcessorDescription}}*"
                 }
               },
               {
                 "type": "section",
                 "text": {
                   "type": "mrkdwn",
                   "text": "*MatchedTerm* {{.MatchedTerm}}\n*ConfigID* {{.ConfigID}}"
                 }
               }
             ]
           }
```

### **Pagerduty**

If enabled, the Pagerduty integration will stream notifications and alerts to the specified Pagerduty API endpoint

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "pagerduty" to send alerts to Pagerduty | Yes |
| endpoint | Pagerduty API endpoint URL | Yes |
| custom\_headers | Used to append some custom headers (such as Authorization etc.) to requests done by the integration | No |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: pagerduty-integration
        type: pagerduty
        endpoint: "https://api.pagerduty.com/XXXXX"
        notify_content:
          advanced_content: |
            {
              "incident": {
                "type": "incident",
                "title": "{{ .Title }}",
                "service": {
                  "id": "<ID of the pagerduty service which can be fetched via services rest API>",
                  "type": "service_reference"
                },
                "body": {
                  "type": "incident_body",
                  "details": "<Message for your incident>"
                }
              }
            }
```

### **Jira**

If enabled, the Jira integration (it makes use of CodeBarrel webhook) will stream notifications and alerts to the specified Jira webhook URL

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "jira" to send alerts to Jira | Yes |
| endpoint | Jira webhook URL | Yes |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: jira-integration
        type: jira
        endpoint: "https://automation.codebarrel.io/pro/hooks/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
        notify_content:
          advanced_content: |
            {
              "data": {
                "title": "{{ .Title }}",
                "message": "{{ .Message }}"
              }
            }
```

### **Service Now**

If enabled, the Service Now integration will stream notifications and alerts to the specified Service Now API endpoint

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "servicenow" to send alerts to Service Now | Yes |
| endpoint | Service Now URL | Yes |
| username | Username for Service Now basic authentication | No |
| password | Password for Service Now basic authentication | No |
| custom\_headers | Used to append some custom headers (such as Authorization etc.) to requests done by the integration | No |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: service-now-integration
        type: servicenow
        endpoint: "https://instance.service-now.com/api/now/table/incident"
        notify_content:
          advanced_content: |
            {
              'short_description': 'Raw POST Anomaly Detected: {{.ProcessorDescription}}',
              'assignment_group':'287ebd7da9fe198100f92cc8d1d2154e',
              'urgency':'2',
              'impact':'2'
            }
```

### **Webhook**

If enabled, the Webhook integration will stream notifications and alerts to the specified Webhook URL

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "webhook" to send alerts to custom Webhook | Yes |
| endpoint | Webhook API endpoint | Yes |
| username | Username for Webhook basic authentication | No |
| password | Password for Webhook basic authentication | No |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: webhook-integration
        type: webhook
        endpoint: "localhost"
        payload:
          signature: "{{.MetricName}}"
          source_id: "{{.Host}}"
          external_id: "{{.EDAC}}"
          manager: "edgedelta"
          source: "{{.Host}}"
          class: "application"
          agent_location: "{{.Host}}"
          type: "{{.SourceType}}"
          agent_time: "{{.Epoch}}"
        notify_content:
          advanced_content: |
            {
              "foo": {
                "title": "{{ .Title }}",
                "message": "{{ .Message }}",
                "foo2": "bar2"
              }
            }
```

### **AWS Lambda**

If enabled, the AWS Lambda integration will stream notifications and alerts to the specified AWS Lambda FaaS endpoint

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "awslambda" to send alerts to AWS Lambda | Yes |
| endpoint | AWS Lambda FaaS Endpoint | Yes |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: aws-lambda-integration
        type: awslambda
        endpoint: "https://XXXXXXXXXX.execute-api.XXXXXXXXX.amazonaws.com/XXXX/XXXXXX"
        notify_content:
          advanced_content: |
            {
              "foo": "bar",
              "title": "{{ .Title }}",
              "message": "{{ .Message }}"
            }
```

### **Azure Functions**

If enabled, the Azure Functions integration will stream notifications and alerts to the specified AWS Lambda FaaS endpoint

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "azurefunctions" to send alerts to Azure Functions | Yes |
| endpoint | Azure Functions FaaS Endpoint | Yes |
| notify\_content | Used to customize the notification content. It supports templating. It is not required but advised to use `advanced_content` subfield. | No |

```yaml
      - name: azure-functions-integration
        type: azurefunctions
        endpoint: "https://XXXXXXXXXX.azurewebsites.net/XXXX/XXXXXX"
        notify_content:
          advanced_content: |
            {
              "foo": "bar",
              "title": "{{ .Title }}",
              "message": "{{ .Message }}"
            }
```

### Examples

```yaml
outputs:
  streams:
      - name: sumo-logic-integration
        type: sumologic
        endpoint: "https://[SumoEndpoint]/receiver/v1/http/[UniqueHTTPCollectorCode]"
  triggers:
      - name: slack-integration
        type: slack
        endpoint: "https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX"
```

## Review Archive Destinations

### **AWS S3**

If enabled, the AWS S3 integration will stream logs to an AWS S3 endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "s3" to send archived logs to AWS S3 | Yes |
| bucket | Target s3 bucket to send archived logs | Yes |
| region | The specified s3 bucket's region | Yes |
| aws\_key\_id | AWS key id that has PutObject permission to target bucket. How do I create an AWS access key? [https://aws.amazon.com/premiumsupport/knowledge-center/create-access-key](https://aws.amazon.com/premiumsupport/knowledge-center/create-access-key) | Yes |
| aws\_sec\_key | AWS secret key id that has PutObject permission to target bucket. How do I create an AWS access key? [https://aws.amazon.com/premiumsupport/knowledge-center/create-access-key](https://aws.amazon.com/premiumsupport/knowledge-center/create-access-key) | Yes |

```yaml
      - name: my-s3
        type: s3
        bucket: testbucket
        region: us-east-2
        aws_key_id: "<add aws key id>"
        aws_sec_key: "<add aws secure key>"
```

### **Azure Blob Storage**

If enabled, the Azure Blob Storage integration will stream logs to an Azure Blob Storage endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "blob" to send archived logs to Azure blob | Yes |
| account\_name | Account Name for the azure account. | Yes |
| account\_key | Account Key for azure account. You can visit [https://docs.microsoft.com/en-us/azure/storage/common/storage-account-keys-manage?tabs=azure-portal](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-keys-manage?tabs=azure-portal) | Yes |
| container | Container to upload. | Yes |
| auto_create_container | Create the container on the service (with no metadata and no public access). | No |

```yaml
      - name: my-blob
        type: blob
        account_name: "<add account name>"
        account_key: "<add account key>"
        container: testcontainer
```

### **Google Cloud Storage**

If enabled, the Google Cloud Storage integration will stream logs to an GCS endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "gcs" to send archived logs to Google Cloud Storage | Yes |
| bucket | Target gcs bucket to send archived logs. | Yes |
| hmac\_access\_key | GCS HMAC Access Key which has permissions to upload files to specified bucket. See [https://cloud.google.com/storage/docs/authentication/managing-hmackeys](https://cloud.google.com/storage/docs/authentication/managing-hmackeys) for details on how to create new keys | Yes |
| hmac\_secret | GCS HMAC secret associated with the access key specified. | Yes |

```yaml
      - name: my-gcs
        type: gcs
        bucket: ed-test-bucket
        hmac_access_key: my_hmac_access_key_123
        hmac_secret: my_hmac_secret_123
```

### **DigitalOcean Spaces**

If enabled, the DigitalOcean Spaces integration will stream logs to an DigitalOcean Spaces endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "dos" to send archived logs to DigitalOcean Spaces | Yes |
| endpoint | DigitalOcean Spaces Endpoint | Yes |
| bucket | Target DOS bucket to send archived logs. | Yes |
| access\_key | Access Key which has permissions to upload files to specified bucket. | Yes |
| secret\_key | Secret Key associated with the access key specified. | Yes |

```yaml
      - name: my-digitalocean-spaces
        type: dos
        endpoint: nyc3.digitaloceanspaces.com
        bucket: ed-test-bucket
        access_key: my_access_key_123
        secret_key: my_secret_key_123
```

### **IBM Object Storage**

If enabled, the IBM Object Storage integration will stream logs to an IBM Object Storage endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "ibmos" to send archived logs to IBM Object Storage | Yes |
| endpoint | IBM Object Storage Endpoint | Yes |
| bucket | Target IBM OS bucket to send archived logs. | Yes |
| access\_key | Access Key which has permissions to upload files to specified bucket. | Yes |
| secret\_key | Secret Key associated with the access key specified. | Yes |

```yaml
      - name: my-ibm-object-storage
        type: ibmos
        endpoint: s3-api.us-geo.objectstorage.softlayer.net
        bucket: ed-test-bucket
        access_key: my_access_key_123
        secret_key: my_secret_key_123
```

### **Minio**

If enabled, the Minio integration will stream logs to an Minio endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "minio" to send archived logs to Minio | Yes |
| endpoint | Minio Endpoint | Yes |
| bucket | Target Minio bucket to send archived logs. | Yes |
| access\_key | Access Key which has permissions to upload files to specified bucket. | Yes |
| secret\_key | Secret Key associated with the access key specified. | Yes |
| disable\_ssl | Disable SSL requirement when pushing logs to Minio endpoint | No |
| s3\_force\_path\_style | Force archive destination to use `{endpoint}/{bucket}` format instead of `{bucket}.{endpoint}/` when reaching buckets`) | No |

```yaml
      - name: my-minio
        type: minio
        endpoint: play.min.io:9000
        bucket: ed-test-bucket
        access_key: my_access_key_123
        secret_key: my_secret_key_123
        disable_ssl: true
        s3_force_path_style: true
```

### **Zenko CloudServer**

If enabled, the Zenko CloudServer integration will stream logs to an CloudServer endpoint.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows. | No |
| type | Must be set to "zenko" to send archived logs to Zenko | Yes |
| endpoint | Zenko Endpoint | Yes |
| bucket | Target Zenko bucket to send archived logs. | Yes |
| access\_key | Access Key which has permissions to upload files to specified bucket. | Yes |
| secret\_key | Secret Key associated with the access key specified. | Yes |

```yaml
      - name: my-zenko-cloudserver
        type: zenko
        endpoint: https://XXXXXXXXXX.sandbox.zenko.io
        bucket: ed-test-bucket
        access_key: my_access_key_123
        secret_key: my_secret_key_123
```

### **Moogsoft**

If enabled, the Moogsoft integration will stream notifications and alerts to the specified Moogsoft URL

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "moogsoft" to send alerts to Moogsoft | Yes |
| endpoint | Moogsoft API endpoint | Yes |
| api_key | Moogsoft API Key. One of the fields API Key or username/password is required. | No |
| username | Username for Moogsoft basic authentication. One of the fields username/password or API Key is required. | No |
| password | Password for Moogsoft basic authentication. One of the fields username/password or API Key is required. | No |
| notify\_content | Used to customize the notification content. It supports templating. Moogsoft only supports `custom_fields` subfield. | No |

```yaml
      - name: moogsoft-default
        type: moogsoft
        endpoint: "https://example.moogsoftaiops.com/events/webhook_webhook1"
        api_key: "moogsoft-apikey"
        notify_content:
          custom_fields:
            "jira-ticket": "ticket"
```

### **Remedy**

If enabled, the Remedy integration will stream notifications and alerts to the specified Remedy URL.

| Key | Description | Required |
| :--- | :--- | :--- |
| name | User defined name of this specific destination, used for mapping this destination to a workflow | No |
| integration\_name | Integration name refers to the organization level integration created on [Integrations page](https://admin.edgedelta.com/integrations). It can be referred in the rest of the config via _integration\_name_ in which case rest of the fields are not required to be set because rest is auto-populated from org level integration spec. In case multiple instances of same integration needs to be added to a config then a custom name can be given to each via _name_ field. In that case name should be used to refer the specific instance of the destination in workflows.  | No |
| type | Must be set to "remedy" to send alerts to Remedy | Yes |
| endpoint | Remedy API endpoint | Yes |
| token | Remedy token. One of the fields token or username/password is required. | No |
| username | Username for Remedy basic authentication. One of the fields username/password or token is required. | No |
| password | Password for Remedy basic authentication. One of the fields username/password or token is required. | No |
| custom\_headers | Used to append some custom headers (such as Authorization etc.) to requests done by the integration | No |
| notify\_content | Used to customize the notification content. It supports templating. Moogsoft only supports `custom_fields` subfield. | No |

```yaml
      - name: remedy-default
        type: remedy
        endpoint: "localhost"
        token: remedy-token
        notify_content:
          custom_fields:
            "test-field": "test"
        custom_headers: 
          X-header1: "test-header"
```

### **Azure Event Hub Trigger**

You can enable this integration to stream notifications and alerts to a specified Event Hub URL. 

> **Note**
> 
> To enable this integration, you must have an Azure AD token. To learn how to create an Azure AD token, review this [document from Microsoft](https://docs.microsoft.com/en-us/rest/api/eventhub/get-azure-active-directory-token).


| Key | Description | Required |
| :--- | :--- | :--- |
| name | This key is the user-defined name of the specific destination. This key is used for mapping this destination to a workflow. | No |
| integration\_name | This key refers to the organization-level integration created on the [Integrations page](https://admin.edgedelta.com/integrations). This key can be referred in the rest of the config via _integration\_name_ . In this case, the rest of the fields are not required to be set because the additional fields are auto-populated from the organization-level integration spec. If there are multiple instances in the same integration that need to be added to a config, then you can create a custom name for each instance via the via _name_ field. In this case, each name should be used to refer to a destination's specific instance in the workflow. | No |
| type | This key must be set to "eventhub" to send alerts to Event Hub. | Yes |
| endpoint | This key is the Event Hub endpoint. | Yes |
| token | This key is the Azure AD token. | Yes |
| custom\_headers | This key appends custom headers, such as Authorization, to requests performed by the integration. | No |
| notify\_content | This key customizes the notification content. This key supports templating. Event Hub only supports the `custom_fields` subfield. | No |

```yaml
       - name: eventhub-test
        type: eventhub
        endpoint: https://eventshub-test.servicebus.windows.net/test/messages
        token: "test-token"
        notify_content:
          custom_fields:
            "test-field": "test"
        custom_headers: 
          X-header1: "test-header"
```





> **Note**
> 
> In the Edge Delta Admin portal, the term **output** is represented by the **Integrations** page. To create an output, access the **Integrations** page. After you create an output, you will be asked to add the output to an existin agent configuration. If you do not have an agent configuration, then you can create the configuration, and then return to the **Integrations** page to add the output to the configuration.  
